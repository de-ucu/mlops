{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import neptune\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers\n",
    "from neptunecontrib.monitoring.keras import NeptuneMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "BATCH_SIZE = 10\n",
    "DATA_ROOT = Path('/', 'data', '02-tfrecords')\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/eawer/animal-classifier/e/AN-45\n"
     ]
    }
   ],
   "source": [
    "neptune.init('eawer/animal-classifier')\n",
    "neptune_experiment = neptune.create_experiment(name='ResNet50V2', tags=['3-classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_memory_growth(gpus[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'label': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    'image': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "}\n",
    "\n",
    "def parse_example(example_proto):\n",
    "    return tf.io.parse_example(example_proto, features)\n",
    "\n",
    "def parse_record(example):\n",
    "    image = tf.io.decode_raw(example['image'], tf.uint8)\n",
    "    image = tf.reshape(image, (-1, IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    label = example['label']\n",
    "\n",
    "    return image, label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "  layers.experimental.preprocessing.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "def prepare_dataset(paths, batch_size, augment=False, seed=SEED):\n",
    "    ds = tf.data.TFRecordDataset(paths, num_parallel_reads=tf.data.AUTOTUNE, compression_type='GZIP')\n",
    "    ds = ds.shuffle(10000, seed=seed, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(parse_example)\n",
    "    ds = ds.batch(batch_size)        \n",
    "    ds = ds.map(parse_record, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if augment:    \n",
    "        ds = ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.repeat(2)\n",
    "\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "train_paths = [str(p) for p in Path(DATA_ROOT, 'train').glob('*.tfrecord')]\n",
    "train_dataset = prepare_dataset(train_paths, BATCH_SIZE, augment=True)\n",
    "\n",
    "test_paths = [str(p) for p in Path(DATA_ROOT, 'test').glob('*.tfrecord')]\n",
    "test_dataset = prepare_dataset(test_paths, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.applications.ResNet50V2(\n",
    "        input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),\n",
    "        classes=3,\n",
    "        weights=None,\n",
    "        classifier_activation='softmax',\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=[tf.losses.SparseCategoricalCrossentropy()], \n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "INFO:tensorflow:batch_all_reduce: 174 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 174 all-reduces with algorithm = nccl, num_packs = 1\n",
      "532/532 [==============================] - 234s 347ms/step - loss: 1.2616 - accuracy: 0.4754 - val_loss: 1.2923 - val_accuracy: 0.4724\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.29226, saving model to /checkpoint/\n",
      "INFO:tensorflow:Assets written to: /checkpoint/assets\n",
      "Epoch 2/50\n",
      "532/532 [==============================] - 184s 339ms/step - loss: 1.0185 - accuracy: 0.5011 - val_loss: 2.1046 - val_accuracy: 0.3706\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.29226\n",
      "Epoch 3/50\n",
      "532/532 [==============================] - 184s 339ms/step - loss: 0.9211 - accuracy: 0.5375 - val_loss: 1.0294 - val_accuracy: 0.4990\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.29226 to 1.02937, saving model to /checkpoint/\n",
      "INFO:tensorflow:Assets written to: /checkpoint/assets\n",
      "Epoch 4/50\n",
      "532/532 [==============================] - 184s 339ms/step - loss: 0.8822 - accuracy: 0.5717 - val_loss: 0.8959 - val_accuracy: 0.5832\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02937 to 0.89591, saving model to /checkpoint/\n",
      "INFO:tensorflow:Assets written to: /checkpoint/assets\n",
      "Epoch 5/50\n",
      "532/532 [==============================] - 184s 339ms/step - loss: 0.8588 - accuracy: 0.5885 - val_loss: 0.8911 - val_accuracy: 0.5757\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.89591 to 0.89114, saving model to /checkpoint/\n",
      "INFO:tensorflow:Assets written to: /checkpoint/assets\n",
      "Epoch 6/50\n",
      "532/532 [==============================] - 184s 339ms/step - loss: 0.8276 - accuracy: 0.6100 - val_loss: 0.8296 - val_accuracy: 0.6063\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.89114 to 0.82959, saving model to /checkpoint/\n",
      "INFO:tensorflow:Assets written to: /checkpoint/assets\n",
      "Epoch 7/50\n",
      "532/532 [==============================] - 184s 339ms/step - loss: 0.7933 - accuracy: 0.6264 - val_loss: 1.0547 - val_accuracy: 0.5196\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.82959\n",
      "Epoch 8/50\n",
      "287/532 [===============>..............] - ETA: 1:21 - loss: 0.7541 - accuracy: 0.6553"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.LearningRateScheduler(tf.keras.experimental.CosineDecayRestarts(0.01, 10, alpha=0.0001)),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='/checkpoint/', save_best_only=True, verbose=1),\n",
    "    NeptuneMonitor(),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, '/model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
